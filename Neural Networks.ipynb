{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c16bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c68220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad583d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Number_of_Bags</th>\n",
       "      <th>Bag_Weight</th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Body</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Clean_Cup</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Total_Cup_Points</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Quakers</th>\n",
       "      <th>Category_Two_Defects</th>\n",
       "      <th>Category_One_Defects</th>\n",
       "      <th>Processing_Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "      <td>150</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Washed / Wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>890</td>\n",
       "      <td>320</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural / Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>890</td>\n",
       "      <td>320</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural / Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>890</td>\n",
       "      <td>320</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.67</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural / Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>890</td>\n",
       "      <td>320</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural / Dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Altitude  Number_of_Bags  Bag_Weight  Aroma  Flavor  Aftertaste  Acidity  \\\n",
       "0      1800             150        60.0   7.33    7.58        7.83     7.75   \n",
       "1       890             320        60.0   7.50    7.75        7.58     7.50   \n",
       "2       890             320        60.0   7.67    7.67        7.58     7.75   \n",
       "3       890             320        60.0   7.67    7.83        7.50     7.67   \n",
       "4       890             320        60.0   7.58    7.67        7.58     7.58   \n",
       "\n",
       "   Body  Balance  Uniformity  Clean_Cup  Sweetness  Total_Cup_Points  \\\n",
       "0  7.75     7.92        10.0       10.0       10.0             84.33   \n",
       "1  7.58     7.50        10.0       10.0       10.0             83.92   \n",
       "2  7.67     7.67        10.0       10.0       10.0             83.75   \n",
       "3  7.67     7.50        10.0       10.0       10.0             83.67   \n",
       "4  7.67     7.58        10.0       10.0       10.0             83.58   \n",
       "\n",
       "   Moisture  Quakers  Category_Two_Defects  Category_One_Defects  \\\n",
       "0      0.11        0                     4                     0   \n",
       "1      0.00        0                     3                     0   \n",
       "2      0.11        0                     5                     0   \n",
       "3      0.11        0                     2                     0   \n",
       "4      0.11        0                     5                     0   \n",
       "\n",
       "  Processing_Method  \n",
       "0      Washed / Wet  \n",
       "1     Natural / Dry  \n",
       "2     Natural / Dry  \n",
       "3     Natural / Dry  \n",
       "4     Natural / Dry  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (\"C:/Users/Aparna Akula/Documents/Machine Learning/numeric_with_label.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1069fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.11.23)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aparna akula\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36009fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.math import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf411f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Number_of_Bags</th>\n",
       "      <th>Bag_Weight</th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Body</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Clean_Cup</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Total_Cup_Points</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Quakers</th>\n",
       "      <th>Category_Two_Defects</th>\n",
       "      <th>Category_One_Defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.255215</td>\n",
       "      <td>0.276290</td>\n",
       "      <td>0.462053</td>\n",
       "      <td>0.864449</td>\n",
       "      <td>0.866270</td>\n",
       "      <td>0.867488</td>\n",
       "      <td>0.875980</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.871566</td>\n",
       "      <td>0.986418</td>\n",
       "      <td>0.985137</td>\n",
       "      <td>0.992153</td>\n",
       "      <td>0.912075</td>\n",
       "      <td>0.577606</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.077641</td>\n",
       "      <td>0.013243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179904</td>\n",
       "      <td>0.237716</td>\n",
       "      <td>0.373589</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.033056</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>0.047129</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.049944</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>0.230019</td>\n",
       "      <td>0.082537</td>\n",
       "      <td>0.114470</td>\n",
       "      <td>0.076498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723429</td>\n",
       "      <td>0.730104</td>\n",
       "      <td>0.744706</td>\n",
       "      <td>0.728438</td>\n",
       "      <td>0.751781</td>\n",
       "      <td>0.708625</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.665369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.845444</td>\n",
       "      <td>0.843529</td>\n",
       "      <td>0.854312</td>\n",
       "      <td>0.870546</td>\n",
       "      <td>0.854312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902691</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.258182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.866286</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>0.872941</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>0.890736</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915592</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.884660</td>\n",
       "      <td>0.891765</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.910926</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926713</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Altitude  Number_of_Bags  Bag_Weight       Aroma      Flavor  \\\n",
       "count  570.000000      570.000000  570.000000  570.000000  570.000000   \n",
       "mean     0.255215        0.276290    0.462053    0.864449    0.866270   \n",
       "std      0.179904        0.237716    0.373589    0.033523    0.035502   \n",
       "min      0.000164        0.001818    0.000000    0.723429    0.730104   \n",
       "25%      0.163934        0.027273    0.025000    0.848000    0.845444   \n",
       "50%      0.213115        0.258182    0.750000    0.866286    0.865052   \n",
       "75%      0.278689        0.500000    0.750000    0.885714    0.884660   \n",
       "max      1.000000        1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Aftertaste     Acidity        Body     Balance  Uniformity   Clean_Cup  \\\n",
       "count  570.000000  570.000000  570.000000  570.000000  570.000000  570.000000   \n",
       "mean     0.867488    0.875980    0.888753    0.871566    0.986418    0.985137   \n",
       "std      0.036832    0.033056    0.031192    0.036974    0.047129    0.071954   \n",
       "min      0.744706    0.728438    0.751781    0.708625    0.600000    0.133000   \n",
       "25%      0.843529    0.854312    0.870546    0.854312    1.000000    1.000000   \n",
       "50%      0.872941    0.874126    0.890736    0.874126    1.000000    1.000000   \n",
       "75%      0.891765    0.893939    0.910926    0.893939    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        Sweetness  Total_Cup_Points    Moisture     Quakers  \\\n",
       "count  570.000000        570.000000  570.000000  570.000000   \n",
       "mean     0.992153          0.912075    0.577606    0.019777   \n",
       "std      0.049944          0.028669    0.230019    0.082537   \n",
       "min      0.133000          0.665369    0.000000    0.000000   \n",
       "25%      1.000000          0.902691    0.588235    0.000000   \n",
       "50%      1.000000          0.915592    0.647059    0.000000   \n",
       "75%      1.000000          0.926713    0.705882    0.000000   \n",
       "max      1.000000          1.000000    1.000000    1.000000   \n",
       "\n",
       "       Category_Two_Defects  Category_One_Defects  \n",
       "count            570.000000            570.000000  \n",
       "mean               0.077641              0.013243  \n",
       "std                0.114470              0.076498  \n",
       "min                0.000000              0.000000  \n",
       "25%                0.000000              0.000000  \n",
       "50%                0.042553              0.000000  \n",
       "75%                0.106383              0.000000  \n",
       "max                1.000000              1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = ['Processing_Method']\n",
    "predictors = list(set(list(df.columns)) - set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "881ae73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processing_Method'] = df['Processing_Method'].astype('category')\n",
    "# Assigning numerical values and storing in another column\n",
    "df['Processing_Method'] = df['Processing_Method'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0a1454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Processing_Method'].values\n",
    "X = df[predictors].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c26a4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 17)\n",
      "(171, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f6b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 5)\n",
    "y_test = to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab0db996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=17, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5984549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "774e6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - 2s 4ms/step - loss: 1.5968 - accuracy: 0.1153\n",
      "Epoch 2/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4770 - accuracy: 0.1704\n",
      "Epoch 3/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3522 - accuracy: 0.1880\n",
      "Epoch 4/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2063 - accuracy: 0.2707\n",
      "Epoch 5/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.6992\n",
      "Epoch 6/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.6992\n",
      "Epoch 7/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6992\n",
      "Epoch 8/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.6992\n",
      "Epoch 9/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.6992\n",
      "Epoch 10/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.6992\n",
      "Epoch 11/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8991 - accuracy: 0.6992\n",
      "Epoch 12/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6992\n",
      "Epoch 13/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.6992\n",
      "Epoch 14/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8952 - accuracy: 0.6992\n",
      "Epoch 15/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.6992\n",
      "Epoch 16/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8930 - accuracy: 0.6992\n",
      "Epoch 17/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.6992\n",
      "Epoch 18/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8897 - accuracy: 0.6992\n",
      "Epoch 19/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.6992\n",
      "Epoch 20/25\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.6992\n",
      "Epoch 21/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6992\n",
      "Epoch 22/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8843 - accuracy: 0.6992\n",
      "Epoch 23/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8811 - accuracy: 0.6992\n",
      "Epoch 24/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8812 - accuracy: 0.6992\n",
      "Epoch 25/25\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8784 - accuracy: 0.6992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156148d8820>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d863dfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "Accuracy on training data: 0.6992481350898743% \n",
      " Error on training data: 0.30075186491012573\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Accuracy on test data: 0.7017543911933899% \n",
      " Error on test data: 0.2982456088066101\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6159104e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37b6c81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2107585 , 0.0331086 , 0.01116286, 0.05692646, 0.6880436 ],\n",
       "       [0.22818327, 0.03554793, 0.01309855, 0.0623435 , 0.66082674],\n",
       "       [0.16742714, 0.02853283, 0.00900558, 0.07493153, 0.72010285],\n",
       "       [0.15116172, 0.02400414, 0.00611119, 0.04273565, 0.77598727],\n",
       "       [0.20443064, 0.03085491, 0.01001905, 0.05548465, 0.6992107 ],\n",
       "       [0.19553982, 0.03372445, 0.01091894, 0.06038417, 0.6994326 ],\n",
       "       [0.1872191 , 0.02921446, 0.0094171 , 0.06239592, 0.71175337],\n",
       "       [0.1487592 , 0.02288316, 0.00589273, 0.04599208, 0.77647287],\n",
       "       [0.21101046, 0.04140779, 0.01542587, 0.07762055, 0.6545354 ],\n",
       "       [0.18902636, 0.0364111 , 0.01184995, 0.06629907, 0.6964135 ],\n",
       "       [0.22279635, 0.04748233, 0.01678539, 0.06376848, 0.6491675 ],\n",
       "       [0.19756113, 0.03436827, 0.01103025, 0.05630015, 0.7007402 ],\n",
       "       [0.19471471, 0.03430086, 0.01048453, 0.05233256, 0.7081674 ],\n",
       "       [0.18163934, 0.03398104, 0.01157859, 0.07955361, 0.69324744],\n",
       "       [0.14734094, 0.02170157, 0.00534215, 0.03994695, 0.7856684 ],\n",
       "       [0.20580995, 0.0367738 , 0.01228039, 0.05751081, 0.6876251 ],\n",
       "       [0.18788327, 0.03565989, 0.0120989 , 0.07188163, 0.6924763 ],\n",
       "       [0.19306216, 0.03837061, 0.0148057 , 0.11705454, 0.63670695],\n",
       "       [0.18209964, 0.03447544, 0.0118897 , 0.07814214, 0.6933931 ],\n",
       "       [0.14814019, 0.0215064 , 0.00534183, 0.040638  , 0.7843736 ],\n",
       "       [0.20300962, 0.03351116, 0.01070446, 0.05502084, 0.6977539 ],\n",
       "       [0.19535904, 0.0350073 , 0.01124998, 0.05732964, 0.70105404],\n",
       "       [0.17866592, 0.03204386, 0.00988437, 0.06102952, 0.7183763 ],\n",
       "       [0.17918229, 0.03071585, 0.00932369, 0.05866067, 0.7221175 ],\n",
       "       [0.1720113 , 0.02929473, 0.00851308, 0.06296688, 0.727214  ],\n",
       "       [0.23160219, 0.03676385, 0.01360633, 0.06211609, 0.6559115 ],\n",
       "       [0.20153981, 0.0340201 , 0.01050763, 0.04922809, 0.7047044 ],\n",
       "       [0.20768504, 0.03735701, 0.0129295 , 0.06608348, 0.6759449 ],\n",
       "       [0.1771639 , 0.0314097 , 0.01003658, 0.07085509, 0.71053475],\n",
       "       [0.19671856, 0.03534417, 0.01153063, 0.05876007, 0.69764656],\n",
       "       [0.19755094, 0.0359147 , 0.01178909, 0.06176178, 0.6929835 ],\n",
       "       [0.18614869, 0.03620561, 0.01241901, 0.07817738, 0.68704927],\n",
       "       [0.1908365 , 0.03213802, 0.00983252, 0.05442386, 0.7127691 ],\n",
       "       [0.20566262, 0.03978363, 0.01527121, 0.08411802, 0.6551645 ],\n",
       "       [0.18469039, 0.03483298, 0.01114952, 0.06956496, 0.69976217],\n",
       "       [0.18412904, 0.03071537, 0.00943875, 0.07138896, 0.7043278 ],\n",
       "       [0.20524774, 0.03862905, 0.01394146, 0.07391121, 0.6682705 ],\n",
       "       [0.19607277, 0.03512855, 0.01125016, 0.05719515, 0.7003534 ],\n",
       "       [0.17869976, 0.03261429, 0.01025453, 0.0645996 , 0.7138318 ],\n",
       "       [0.18573861, 0.03379939, 0.01166067, 0.08130895, 0.6874924 ],\n",
       "       [0.17739226, 0.02760391, 0.00793956, 0.05119042, 0.73587394],\n",
       "       [0.1873026 , 0.03853288, 0.01380677, 0.08079211, 0.67956567],\n",
       "       [0.16588615, 0.02998774, 0.00898925, 0.06320883, 0.731928  ],\n",
       "       [0.21320088, 0.05604846, 0.02112351, 0.10109366, 0.60853344],\n",
       "       [0.19335343, 0.03322528, 0.01057527, 0.05684439, 0.7060016 ],\n",
       "       [0.20002885, 0.03611475, 0.01150801, 0.05389533, 0.698453  ],\n",
       "       [0.19104525, 0.03346872, 0.01024289, 0.05316687, 0.71207625],\n",
       "       [0.19007677, 0.02995388, 0.00979729, 0.06158138, 0.7085907 ],\n",
       "       [0.18273313, 0.03484229, 0.01121818, 0.0684043 , 0.7028021 ],\n",
       "       [0.1851846 , 0.03009986, 0.00918037, 0.05694929, 0.7185859 ],\n",
       "       [0.18887424, 0.03603721, 0.01173372, 0.06585837, 0.6974964 ],\n",
       "       [0.18600471, 0.03460483, 0.01187987, 0.07888784, 0.6886227 ],\n",
       "       [0.18549345, 0.03737483, 0.01346739, 0.08460994, 0.6790544 ],\n",
       "       [0.20296054, 0.03358323, 0.01029672, 0.04799039, 0.70516914],\n",
       "       [0.19854443, 0.02964066, 0.00962361, 0.05287689, 0.70931447],\n",
       "       [0.17891337, 0.03268851, 0.0101934 , 0.0632268 , 0.71497786],\n",
       "       [0.18076524, 0.03370209, 0.01091507, 0.0708039 , 0.70381373],\n",
       "       [0.18831888, 0.03676004, 0.01320595, 0.08319418, 0.6785209 ],\n",
       "       [0.18234839, 0.03569717, 0.0125687 , 0.08148735, 0.68789834],\n",
       "       [0.20615792, 0.03389079, 0.0128705 , 0.07908066, 0.6680001 ],\n",
       "       [0.19381803, 0.0319984 , 0.00939997, 0.04852718, 0.7162564 ],\n",
       "       [0.22001712, 0.03943957, 0.01494958, 0.07121524, 0.6543784 ],\n",
       "       [0.18055628, 0.03358729, 0.01187466, 0.08472125, 0.68926054],\n",
       "       [0.19683471, 0.03519426, 0.01158793, 0.05962722, 0.6967559 ],\n",
       "       [0.14659789, 0.02174223, 0.00539623, 0.04047133, 0.7857923 ],\n",
       "       [0.19708203, 0.03550546, 0.01144408, 0.05810209, 0.6978664 ],\n",
       "       [0.1838361 , 0.03428836, 0.01138366, 0.07363846, 0.69685346],\n",
       "       [0.19687447, 0.03324584, 0.01041691, 0.05359926, 0.70586354],\n",
       "       [0.19297847, 0.03972478, 0.01492926, 0.08906114, 0.66330636],\n",
       "       [0.1878967 , 0.03033804, 0.0100411 , 0.06628294, 0.7054412 ],\n",
       "       [0.19595793, 0.03558758, 0.01235987, 0.0750211 , 0.6810735 ],\n",
       "       [0.18913905, 0.03497156, 0.01185614, 0.0754993 , 0.68853396],\n",
       "       [0.18584439, 0.03510313, 0.01193977, 0.07640885, 0.69070387],\n",
       "       [0.1903613 , 0.03244973, 0.01122198, 0.07006175, 0.6959052 ],\n",
       "       [0.17549206, 0.03339608, 0.01063857, 0.06964216, 0.71083117],\n",
       "       [0.1902339 , 0.03368313, 0.01060188, 0.0551354 , 0.7103457 ],\n",
       "       [0.18820643, 0.03593074, 0.01223689, 0.07316846, 0.69045746],\n",
       "       [0.18993294, 0.03461263, 0.01102195, 0.05692739, 0.7075051 ],\n",
       "       [0.18535753, 0.03375985, 0.01164453, 0.08051514, 0.6887229 ],\n",
       "       [0.18170987, 0.03433956, 0.01218942, 0.08295359, 0.6888076 ],\n",
       "       [0.18474884, 0.03352369, 0.01066695, 0.06451122, 0.70654935],\n",
       "       [0.200262  , 0.03738378, 0.01270495, 0.06506562, 0.68458366],\n",
       "       [0.18835081, 0.03523521, 0.01165388, 0.06529973, 0.6994603 ],\n",
       "       [0.13445425, 0.01736608, 0.00390142, 0.03786428, 0.806414  ],\n",
       "       [0.19640392, 0.0331308 , 0.01036407, 0.05397558, 0.70612556],\n",
       "       [0.19024362, 0.03671389, 0.01275086, 0.07701292, 0.68327874],\n",
       "       [0.22874813, 0.03564131, 0.01314584, 0.06222759, 0.66023713],\n",
       "       [0.18406971, 0.03819578, 0.01351735, 0.07998826, 0.6842289 ],\n",
       "       [0.13949266, 0.02042041, 0.00482898, 0.04202454, 0.7932334 ],\n",
       "       [0.1768914 , 0.03198173, 0.00990532, 0.06642047, 0.7148011 ],\n",
       "       [0.18123533, 0.03203267, 0.01000547, 0.06186173, 0.7148648 ],\n",
       "       [0.17407888, 0.0327488 , 0.01045692, 0.0681463 , 0.7145691 ],\n",
       "       [0.12616353, 0.01638153, 0.00363753, 0.04004847, 0.813769  ],\n",
       "       [0.18461715, 0.02916575, 0.00931956, 0.06352671, 0.71337086],\n",
       "       [0.18544078, 0.03276894, 0.0102625 , 0.06026154, 0.7112663 ],\n",
       "       [0.20328337, 0.03652496, 0.01217226, 0.05947003, 0.6885494 ],\n",
       "       [0.17574675, 0.03095275, 0.01006163, 0.07261493, 0.71062386],\n",
       "       [0.18680051, 0.03532345, 0.01215584, 0.07815506, 0.68756515],\n",
       "       [0.18963371, 0.04052777, 0.01504782, 0.08621538, 0.66857535],\n",
       "       [0.20149994, 0.04566819, 0.01873286, 0.13513416, 0.5989648 ],\n",
       "       [0.1964619 , 0.03645518, 0.01219939, 0.06489468, 0.6899888 ],\n",
       "       [0.18534115, 0.03544347, 0.01231473, 0.0799788 , 0.6869218 ],\n",
       "       [0.18701635, 0.03708623, 0.01287003, 0.07581789, 0.6872095 ],\n",
       "       [0.18852   , 0.034241  , 0.01041679, 0.05268185, 0.7141404 ],\n",
       "       [0.17742534, 0.03342895, 0.01076655, 0.06908228, 0.70929694],\n",
       "       [0.19678742, 0.03437012, 0.01065413, 0.05382176, 0.7043665 ],\n",
       "       [0.18716696, 0.03690008, 0.0128466 , 0.07877211, 0.68431425],\n",
       "       [0.18763845, 0.03671456, 0.01364396, 0.0875866 , 0.6744164 ],\n",
       "       [0.18222697, 0.03399005, 0.01199806, 0.08174984, 0.69003505],\n",
       "       [0.18266366, 0.0290699 , 0.00913567, 0.06025705, 0.71887374],\n",
       "       [0.18669449, 0.03140714, 0.01083601, 0.07217652, 0.69888586],\n",
       "       [0.18158291, 0.03373609, 0.01197407, 0.08422776, 0.6884792 ],\n",
       "       [0.19821453, 0.03704323, 0.01254385, 0.06500726, 0.6871911 ],\n",
       "       [0.1961333 , 0.0312954 , 0.01054933, 0.06427641, 0.6977456 ],\n",
       "       [0.20113067, 0.03569084, 0.01157802, 0.05576162, 0.69583887],\n",
       "       [0.17570993, 0.03344047, 0.01085657, 0.07189027, 0.7081027 ],\n",
       "       [0.20577526, 0.03064895, 0.01004926, 0.05640315, 0.69712335],\n",
       "       [0.1613075 , 0.02629583, 0.00713043, 0.04949937, 0.75576687],\n",
       "       [0.18731064, 0.0291935 , 0.00915936, 0.06084943, 0.71348715],\n",
       "       [0.18711822, 0.03048706, 0.00998427, 0.06329241, 0.709118  ],\n",
       "       [0.16011575, 0.02542203, 0.00684061, 0.04836755, 0.7592541 ],\n",
       "       [0.17540827, 0.03317782, 0.01070144, 0.07106718, 0.7096453 ],\n",
       "       [0.1694045 , 0.02942003, 0.0092173 , 0.08072785, 0.7112304 ],\n",
       "       [0.19465326, 0.03141007, 0.01044581, 0.06183419, 0.70165664],\n",
       "       [0.18171741, 0.03280094, 0.01049267, 0.06553696, 0.70945203],\n",
       "       [0.14481585, 0.02032702, 0.00492811, 0.03961256, 0.7903164 ],\n",
       "       [0.17490615, 0.02961522, 0.00929672, 0.07137063, 0.7148113 ],\n",
       "       [0.18070371, 0.0338608 , 0.01148039, 0.07793806, 0.6960171 ],\n",
       "       [0.18609472, 0.03693219, 0.01281339, 0.0856268 , 0.67853284],\n",
       "       [0.18827774, 0.03125126, 0.01040201, 0.0676827 , 0.7023863 ],\n",
       "       [0.1985044 , 0.03662462, 0.0141384 , 0.08760709, 0.6631255 ],\n",
       "       [0.19190942, 0.03737945, 0.01402065, 0.08858553, 0.66810495],\n",
       "       [0.15914966, 0.02439103, 0.00636284, 0.04225749, 0.767839  ],\n",
       "       [0.19431025, 0.03421387, 0.01116408, 0.06161578, 0.69869596],\n",
       "       [0.18247771, 0.03337101, 0.01162065, 0.08242209, 0.69010854],\n",
       "       [0.18104222, 0.03348562, 0.0108311 , 0.06901744, 0.7056236 ],\n",
       "       [0.16593061, 0.02992015, 0.00886023, 0.0629499 , 0.73233914],\n",
       "       [0.1791918 , 0.03371607, 0.01181838, 0.08226973, 0.69300395],\n",
       "       [0.18140084, 0.03503523, 0.01160158, 0.0726503 , 0.69931203],\n",
       "       [0.14611623, 0.02123338, 0.00517285, 0.04043884, 0.7870387 ],\n",
       "       [0.19302665, 0.03841372, 0.0138673 , 0.08310258, 0.67158973],\n",
       "       [0.18330427, 0.03326372, 0.01112361, 0.0760231 , 0.69628525],\n",
       "       [0.13801576, 0.0183462 , 0.00419394, 0.04008787, 0.7993562 ],\n",
       "       [0.19033787, 0.03661913, 0.01293315, 0.07494701, 0.68516284],\n",
       "       [0.20760652, 0.03739944, 0.01267926, 0.05796416, 0.6843506 ],\n",
       "       [0.1453043 , 0.02113404, 0.00517366, 0.03999199, 0.78839594],\n",
       "       [0.2077869 , 0.03410262, 0.01125565, 0.05658524, 0.6902696 ],\n",
       "       [0.19329214, 0.03181157, 0.01067172, 0.06266499, 0.70155954],\n",
       "       [0.1889377 , 0.0299472 , 0.00999659, 0.06555444, 0.7055641 ],\n",
       "       [0.18737727, 0.02991829, 0.00970312, 0.06009068, 0.71291065],\n",
       "       [0.1854088 , 0.03482626, 0.01134503, 0.06606259, 0.70235735],\n",
       "       [0.19185558, 0.0344105 , 0.01082929, 0.05545464, 0.70745   ],\n",
       "       [0.19590926, 0.03408438, 0.01081104, 0.05621019, 0.70298517],\n",
       "       [0.20385346, 0.03645935, 0.01230181, 0.06115224, 0.6862332 ],\n",
       "       [0.2146443 , 0.03955987, 0.01453849, 0.07043055, 0.6608268 ],\n",
       "       [0.1824048 , 0.03310845, 0.01141998, 0.07642449, 0.6966423 ],\n",
       "       [0.20652431, 0.03226237, 0.01036987, 0.05465053, 0.6961929 ],\n",
       "       [0.18357104, 0.03572997, 0.01229457, 0.07669026, 0.69171417],\n",
       "       [0.20537677, 0.03740951, 0.01259847, 0.05920542, 0.6854098 ],\n",
       "       [0.18275109, 0.03528754, 0.01200185, 0.07728923, 0.6926702 ],\n",
       "       [0.20226896, 0.03584868, 0.01185099, 0.05941698, 0.69061434],\n",
       "       [0.19388044, 0.03416678, 0.01088147, 0.05580585, 0.70526546],\n",
       "       [0.18464348, 0.03426239, 0.01105089, 0.06572867, 0.70431453],\n",
       "       [0.19072033, 0.03024478, 0.00993472, 0.06295848, 0.7061417 ],\n",
       "       [0.1775647 , 0.03229019, 0.01109795, 0.0799847 , 0.6990624 ],\n",
       "       [0.18217655, 0.03537458, 0.01182586, 0.07336819, 0.6972548 ],\n",
       "       [0.18853816, 0.03688995, 0.014253  , 0.0962005 , 0.66411835],\n",
       "       [0.1364122 , 0.01758505, 0.00395044, 0.0398676 , 0.80218476],\n",
       "       [0.18873262, 0.03626009, 0.01263085, 0.07797926, 0.68439716],\n",
       "       [0.19194625, 0.02758313, 0.00852395, 0.05291879, 0.7190279 ],\n",
       "       [0.20577712, 0.03624463, 0.01171228, 0.05752973, 0.6887362 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4be7a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_maxes = pred_test.max(axis=1).reshape(-1, 1)\n",
    "np.where(pred_test == row_maxes, 1, 0)\n",
    "#np.where(pred_test == row_maxes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a486a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[:] = np.where(pred_test == row_maxes, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4909b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "781c3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pd.DataFrame(pred_test, columns = [0,1,2,3,4])\n",
    "y_test = pd.DataFrame(y_test, columns = [0,1,2,3,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f02f753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      4\n",
       "3      4\n",
       "4      4\n",
       "      ..\n",
       "166    4\n",
       "167    4\n",
       "168    0\n",
       "169    4\n",
       "170    4\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54a76f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_test.idxmax(1)\n",
    "y_test_array = y_test.idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a745f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :  tf.Tensor(\n",
      "[[  0   0   0   0  31]\n",
      " [  0   0   0   0   5]\n",
      " [  0   0   0   0   4]\n",
      " [  0   0   0   0  11]\n",
      " [  0   0   0   0 120]], shape=(5, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix : \", confusion_matrix(y_test_array,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e872736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
